{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mae25-create/data_visualization-analysis_practice/blob/main/Expedia_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dS7_YVwXrI6d"
      },
      "source": [
        "# Applying Neural Networks to the Expedia Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32w6RA_wo6FB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ufwns6wnpIq2"
      },
      "outputs": [],
      "source": [
        "df_clean = pd.read_csv(\"expedia_clean.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXo8afRPpLbL"
      },
      "source": [
        "The data preparation is going to be identical to the one we did in the last class (Random Forests and Gradient Boosting)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwmV96SSqBfo"
      },
      "outputs": [],
      "source": [
        "# Converting the dates to date format (as it was in object format)\n",
        "\n",
        "df_clean[\"date_time\"] = pd.to_datetime(df_clean[\"date_time\"])\n",
        "df_clean[\"srch_ci\"] = pd.to_datetime(df_clean[\"srch_ci\"])\n",
        "df_clean[\"srch_co\"] = pd.to_datetime(df_clean[\"srch_co\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZUvHaK2qDJh",
        "outputId": "9dcabc20-9319-42a1-ca64-a721f4d1ec8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 96534 entries, 0 to 96533\n",
            "Data columns (total 30 columns):\n",
            " #   Column                    Non-Null Count  Dtype         \n",
            "---  ------                    --------------  -----         \n",
            " 0   date_time                 96534 non-null  datetime64[ns]\n",
            " 1   site_name                 96534 non-null  int64         \n",
            " 2   posa_continent            96534 non-null  int64         \n",
            " 3   user_location_country     96534 non-null  object        \n",
            " 4   user_location_region      96534 non-null  int64         \n",
            " 5   user_location_city        96534 non-null  int64         \n",
            " 6   user_id                   96534 non-null  int64         \n",
            " 7   is_mobile                 96534 non-null  int64         \n",
            " 8   is_package                96534 non-null  int64         \n",
            " 9   channel                   96534 non-null  int64         \n",
            " 10  srch_ci                   96534 non-null  datetime64[ns]\n",
            " 11  srch_co                   96534 non-null  datetime64[ns]\n",
            " 12  srch_adults_cnt           96534 non-null  int64         \n",
            " 13  srch_children_cnt         96534 non-null  int64         \n",
            " 14  srch_rm_cnt               96534 non-null  int64         \n",
            " 15  srch_destination_id       96534 non-null  int64         \n",
            " 16  srch_destination_type_id  96534 non-null  int64         \n",
            " 17  is_booking                96534 non-null  int64         \n",
            " 18  cnt                       96534 non-null  int64         \n",
            " 19  hotel_continent           96534 non-null  int64         \n",
            " 20  hotel_country             96534 non-null  object        \n",
            " 21  hotel_market              96534 non-null  int64         \n",
            " 22  hotel_cluster             96534 non-null  int64         \n",
            " 23  year                      96534 non-null  int64         \n",
            " 24  month                     96534 non-null  int64         \n",
            " 25  day_of_week               96534 non-null  object        \n",
            " 26  time                      96534 non-null  object        \n",
            " 27  hour                      96534 non-null  int64         \n",
            " 28  stay_length               96534 non-null  int64         \n",
            " 29  search_lead_time          96534 non-null  int64         \n",
            "dtypes: datetime64[ns](3), int64(23), object(4)\n",
            "memory usage: 22.1+ MB\n"
          ]
        }
      ],
      "source": [
        "df_clean.drop(columns=[\"Unnamed: 0\", \"Unnamed: 0.1\"], inplace=True)\n",
        "df_clean.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lE0dOlvQqHkc"
      },
      "source": [
        "Now, as we mentioned yesterday, the cross validation approach is not suitable, since the data has a time structure. We cannot use future data to predict past data, it doesn't make any sense. So what we are going to do is the following:\n",
        "\n",
        "Again, we are going to split into 70% training, 15% validation, and 15% testing, based on the time stamp. This means, the first 70% of the data for training, the next 15% for validation, and the last 15% for testing. By doing so, we are training on past data to predict future data, which does make sense."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSX0WcitqFK3"
      },
      "outputs": [],
      "source": [
        "df = df_clean.copy()\n",
        "\n",
        "# Ensure the data is sorted by search date\n",
        "df = df.sort_values(by=\"date_time\")\n",
        "\n",
        "# Extract features from srch_ci (Check-in Date)\n",
        "df[\"srch_ci_year\"] = df[\"srch_ci\"].dt.year\n",
        "df[\"srch_ci_month\"] = df[\"srch_ci\"].dt.month\n",
        "df[\"srch_ci_day\"] = df[\"srch_ci\"].dt.day\n",
        "df[\"srch_ci_dow\"] = df[\"srch_ci\"].dt.dayofweek  # Monday=0, Sunday=6\n",
        "df[\"srch_ci_hour\"] = df[\"srch_ci\"].dt.hour\n",
        "\n",
        "# Extract features from srch_co (Check-out Date)\n",
        "df[\"srch_co_year\"] = df[\"srch_co\"].dt.year\n",
        "df[\"srch_co_month\"] = df[\"srch_co\"].dt.month\n",
        "df[\"srch_co_day\"] = df[\"srch_co\"].dt.day\n",
        "df[\"srch_co_dow\"] = df[\"srch_co\"].dt.dayofweek\n",
        "df[\"srch_co_hour\"] = df[\"srch_co\"].dt.hour\n",
        "\n",
        "# Delete time objects\n",
        "df = df.drop(columns=[\"srch_ci\", \"srch_co\", \"date_time\", \"time\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_evNZWFrF46"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Dealing with categorical variables\n",
        "\n",
        "day_map = {\n",
        "    \"Monday\": 0, \"Tuesday\": 1, \"Wednesday\": 2, \"Thursday\": 3,\n",
        "    \"Friday\": 4, \"Saturday\": 5, \"Sunday\": 6\n",
        "}\n",
        "df[\"day_of_week\"] = df[\"day_of_week\"].map(day_map)\n",
        "\n",
        "categorical_cols = [\"user_location_country\", \"hotel_country\"]\n",
        "\n",
        "label_encoders = {}\n",
        "\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "    label_encoders[col] = le  # Save encoder if you want to inverse transform later"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQXIHVgCrHxe"
      },
      "outputs": [],
      "source": [
        "# Define the split index (70% training, 15% validation, 15% testing)\n",
        "n_total = len(df)\n",
        "train_end = int(n_total * 0.70)\n",
        "val_end = int(n_total * 0.85)\n",
        "\n",
        "# Split the data\n",
        "X_train = df.iloc[:train_end].drop(\"is_booking\", axis=1)\n",
        "y_train = df.iloc[:train_end][\"is_booking\"]\n",
        "\n",
        "X_val = df.iloc[train_end:val_end].drop(\"is_booking\", axis=1)\n",
        "y_val = df.iloc[train_end:val_end][\"is_booking\"]\n",
        "\n",
        "X_test = df.iloc[val_end:].drop(\"is_booking\", axis=1)\n",
        "y_test = df.iloc[val_end:][\"is_booking\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbswIP98rPLi",
        "outputId": "19c15fc0-01a1-42db-c620-1b8532046e84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYKTSyRYtPrp"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5P7P7SaHtbqS"
      },
      "source": [
        "We haven't seen anything related to adaptative learning rates, so we'll fix a value for a learning rate $\\eta=0.01$. Also, we'll use a neural network with two hidden layers with the ReLU as the activation function. The first hidden layer will have 30 neurons and the second will have 15. Finally, since we want the output to be a probability (between zero and one), we'll use the sigmoid function as the activation function for the output layer.\n",
        "\n",
        "As we explained before, the loss function for this type of problems is the binary cross-entropy loss. We haven't introduced the concept of **epoch** before, but it's finally time! We had that every time we update the model's parameters, we had an iteration. The epoch is a slightly different concept. An epoch is one complete pass through the entire training dataset.\n",
        "\n",
        "Let's use an example to explain it. Let's say we have 1,000 training samples and the mini-batch size is 100 samples. For each mini-batch (100 samples), the model will make an update after computing the gradient and loss for that mini-batch. In each epoch, the model will go through all 1,000 training samples, which means it will process 10 mini-batches (since $1000/100 = 10$ mini-batches).\n",
        "\n",
        "To sum up: 1 iteration $=$ 1 mini-batch update. 1 epoch $=$ 1 full pass through the dataset (10 iterations in the previous example).\n",
        "\n",
        "In Keras, we'll usually set the number of epochs instead of the number of iterations. In our case, we have 455 training rows. And we'll set the size of the mini-batches to 16. So we would have $455/16=28.4\\simeq 29$ iterations per epoch (we round up to the next number to ensure that all data is processed, to complete an epoch)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-TwBhG2tTKy",
        "outputId": "80f7b343-86f7-44e7-e67d-406d99750277"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 719726430921196887728979968.0000 - recall: 0.3981\n",
            "Epoch 2/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.6955 - recall: 0.4924\n",
            "Epoch 3/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.6893 - recall: 0.2770\n",
            "Epoch 4/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.6922 - recall: 0.2518\n",
            "Epoch 5/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.6987 - recall: 0.5765\n",
            "Epoch 6/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 0.6864 - recall: 0.1926\n",
            "Epoch 7/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.6961 - recall: 0.7757\n",
            "Epoch 8/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.6925 - recall: 0.2654\n",
            "Epoch 9/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.6978 - recall: 0.5494\n",
            "Epoch 10/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.6962 - recall: 0.3435\n",
            "Epoch 11/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.6911 - recall: 0.3418\n",
            "Epoch 12/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.6902 - recall: 0.4332\n",
            "Epoch 13/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.6953 - recall: 0.6435\n",
            "Epoch 14/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.6980 - recall: 0.7692\n",
            "Epoch 15/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.6857 - recall: 0.2822\n",
            "Epoch 16/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.6994 - recall: 0.8902\n",
            "Epoch 17/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 0.6909 - recall: 0.3845\n",
            "Epoch 18/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.6953 - recall: 0.5588\n",
            "Epoch 19/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.6898 - recall: 0.2389\n",
            "Epoch 20/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 0.6888 - recall: 0.3741\n",
            "Epoch 21/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.6863 - recall: 0.1898\n",
            "Epoch 22/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.6987 - recall: 0.5663\n",
            "Epoch 23/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 0.6866 - recall: 0.2347\n",
            "Epoch 24/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 0.6956 - recall: 0.6835\n",
            "Epoch 25/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.6917 - recall: 0.4378\n",
            "Epoch 26/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 0.6932 - recall: 0.4769\n",
            "Epoch 27/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.7023 - recall: 0.7049\n",
            "Epoch 28/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 0.6895 - recall: 0.1689\n",
            "Epoch 29/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 0.6907 - recall: 0.3382\n",
            "Epoch 30/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 0.6936 - recall: 0.2753\n",
            "Epoch 31/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 0.6973 - recall: 0.6174\n",
            "Epoch 32/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.6956 - recall: 0.4114\n",
            "Epoch 33/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 0.6938 - recall: 0.3550\n",
            "Epoch 34/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.6980 - recall: 0.5497\n",
            "Epoch 35/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 0.6884 - recall: 0.2070\n",
            "Epoch 36/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 0.6992 - recall: 0.8662\n",
            "Epoch 37/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.6876 - recall: 0.2967\n",
            "Epoch 38/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 0.6936 - recall: 0.5074\n",
            "Epoch 39/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 0.6968 - recall: 0.7034\n",
            "Epoch 40/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 0.6921 - recall: 0.3347\n",
            "Epoch 41/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 0.6867 - recall: 0.1655\n",
            "Epoch 42/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 0.6995 - recall: 0.5681\n",
            "Epoch 43/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.6984 - recall: 0.5301\n",
            "Epoch 44/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 0.6930 - recall: 0.5320\n",
            "Epoch 45/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.7004 - recall: 0.7114\n",
            "Epoch 46/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.6884 - recall: 0.3176\n",
            "Epoch 47/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.6871 - recall: 0.5873\n",
            "Epoch 48/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 0.7000 - recall: 0.8506\n",
            "Epoch 49/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 0.6946 - recall: 0.2682\n",
            "Epoch 50/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.7010 - recall: 0.8576\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Test Accuracy: 0.9349\n",
            "Test Precision: 0.0000\n",
            "Test Recall: 0.0000\n",
            "Test F1 Score: 0.0000\n",
            "Test Confusion Matrix: [[13537     0]\n",
            " [  943     0]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.optimizers import SGD\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "sgd_optimizer = SGD(learning_rate=0.01)\n",
        "\n",
        "# Compute class weights\n",
        "class_weights = class_weight.compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(y_train),\n",
        "    y=y_train\n",
        ")\n",
        "class_weight_dict = dict(enumerate(class_weights))\n",
        "\n",
        "# Define the neural network model, be free to change the # of neuron you want to use\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(30, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    keras.layers.Dense(15, activation='relu'),\n",
        "    keras.layers.Dense(1, activation='sigmoid')  # Sigmoid for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=sgd_optimizer, loss='binary_crossentropy', metrics=['recall'])\n",
        "\n",
        "# Train the model: choose only 16 out of 1000 to train\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=16, verbose=1,\n",
        "                    class_weight=class_weight_dict)\n",
        "# The verbose=1 will show us what's happening in every epoch.\n",
        "# Take a look at the output. Thanks to the verbose=1, you'll see that in each epoch we have 29 iterations, as expected.\n",
        "\n",
        "# Evaluate the model on test data\n",
        "y_pred = (model.predict(X_val) > 0.5).astype(\"int32\") # The threshold to determine if the target is 0 or 1 is 0.5 (remember: probabilities).\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "precision = precision_score(y_val, y_pred)\n",
        "recall = recall_score(y_val, y_pred)\n",
        "f1 = f1_score(y_val, y_pred)\n",
        "cm = confusion_matrix(y_val, y_pred)\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Test Precision: {precision:.4f}\")\n",
        "print(f\"Test Recall: {recall:.4f}\")\n",
        "print(f\"Test F1 Score: {f1:.4f}\")\n",
        "print(f\"Test Confusion Matrix: {cm}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JCmSoPNy9WW"
      },
      "source": [
        "What are we seeing here? It went pretty quick, but the results are terrible! We are just saying that everybody is not booking.\n",
        "\n",
        "We'll see that the problem is that the data is not normalized (or standardized). Let's do it, see what happens, and then explain why not doing it is a problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbut6Dgv7eWb"
      },
      "outputs": [],
      "source": [
        "# Standardlize / Normalize the data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0Sw6oNTy4UB",
        "outputId": "28956e9c-846e-4325-803b-a3e57169de8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.6717 - recall: 0.6369\n",
            "Epoch 2/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.6087 - recall: 0.7359\n",
            "Epoch 3/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 0.5763 - recall: 0.7657\n",
            "Epoch 4/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 0.5774 - recall: 0.8034\n",
            "Epoch 5/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.5692 - recall: 0.8130\n",
            "Epoch 6/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.5638 - recall: 0.8228\n",
            "Epoch 7/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.5627 - recall: 0.8205\n",
            "Epoch 8/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.5640 - recall: 0.8148\n",
            "Epoch 9/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.5598 - recall: 0.8074\n",
            "Epoch 10/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 0.5619 - recall: 0.8136\n",
            "Epoch 11/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 0.5552 - recall: 0.8104\n",
            "Epoch 12/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.5503 - recall: 0.8205\n",
            "Epoch 13/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.5563 - recall: 0.8127\n",
            "Epoch 14/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.5610 - recall: 0.8039\n",
            "Epoch 15/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.5532 - recall: 0.8333\n",
            "Epoch 16/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.5544 - recall: 0.8084\n",
            "Epoch 17/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.5439 - recall: 0.8133\n",
            "Epoch 18/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.5486 - recall: 0.8223\n",
            "Epoch 19/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.5456 - recall: 0.8113\n",
            "Epoch 20/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.5465 - recall: 0.8318\n",
            "Epoch 21/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 0.5394 - recall: 0.8176\n",
            "Epoch 22/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.5469 - recall: 0.8199\n",
            "Epoch 23/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.5419 - recall: 0.8235\n",
            "Epoch 24/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.5386 - recall: 0.8164\n",
            "Epoch 25/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.5384 - recall: 0.8250\n",
            "Epoch 26/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.5365 - recall: 0.8262\n",
            "Epoch 27/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 0.5390 - recall: 0.8208\n",
            "Epoch 28/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.5404 - recall: 0.8409\n",
            "Epoch 29/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.5355 - recall: 0.8149\n",
            "Epoch 30/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 0.5351 - recall: 0.8248\n",
            "Epoch 31/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.5327 - recall: 0.8170\n",
            "Epoch 32/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.5351 - recall: 0.8279\n",
            "Epoch 33/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.5426 - recall: 0.8323\n",
            "Epoch 34/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.5345 - recall: 0.8235\n",
            "Epoch 35/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.5263 - recall: 0.8056\n",
            "Epoch 36/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.5353 - recall: 0.8290\n",
            "Epoch 37/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.5322 - recall: 0.8243\n",
            "Epoch 38/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - loss: 0.5323 - recall: 0.8057\n",
            "Epoch 39/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.5330 - recall: 0.8322\n",
            "Epoch 40/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.5275 - recall: 0.8203\n",
            "Epoch 41/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.5334 - recall: 0.8225\n",
            "Epoch 42/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.5237 - recall: 0.8215\n",
            "Epoch 43/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 0.5311 - recall: 0.8247\n",
            "Epoch 44/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 0.5293 - recall: 0.8316\n",
            "Epoch 45/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.5293 - recall: 0.8156\n",
            "Epoch 46/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.5241 - recall: 0.8273\n",
            "Epoch 47/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.5287 - recall: 0.8178\n",
            "Epoch 48/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.5253 - recall: 0.8168\n",
            "Epoch 49/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.5207 - recall: 0.8149\n",
            "Epoch 50/50\n",
            "\u001b[1m4224/4224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.5208 - recall: 0.8142\n"
          ]
        }
      ],
      "source": [
        "sgd_optimizer = SGD(learning_rate=0.01)\n",
        "\n",
        "# Compute class weights\n",
        "class_weights = class_weight.compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(y_train),\n",
        "    y=y_train\n",
        ")\n",
        "class_weight_dict = dict(enumerate(class_weights))\n",
        "\n",
        "# Define the neural network model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(30, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    keras.layers.Dense(15, activation='relu'),\n",
        "    keras.layers.Dense(1, activation='sigmoid')  # Sigmoid for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=sgd_optimizer, loss='binary_crossentropy', metrics=['recall'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train_scaled, y_train, epochs=50, batch_size=16, verbose=1,\n",
        "                    class_weight = class_weight_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhLGeC919uAa",
        "outputId": "c7a06455-5263-4ba8-879a-b4d9d771ae7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Validation Accuracy: 0.6901\n",
            "Validation Precision: 0.1064\n",
            "Validation Recall: 0.5080\n",
            "Validation F1 Score: 0.1759\n",
            "Validation Confusion Matrix: [[9514 4023]\n",
            " [ 464  479]]\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on test data\n",
        "y_pred = (model.predict(X_val_scaled) > 0.5).astype(\"int32\")\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "precision = precision_score(y_val, y_pred)\n",
        "recall = recall_score(y_val, y_pred)\n",
        "f1 = f1_score(y_val, y_pred)\n",
        "cm = confusion_matrix(y_val, y_pred)\n",
        "\n",
        "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Validation Precision: {precision:.4f}\")\n",
        "print(f\"Validation Recall: {recall:.4f}\")\n",
        "print(f\"Validation F1 Score: {f1:.4f}\")\n",
        "print(f\"Validation Confusion Matrix: {cm}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Insight\n",
        "\n",
        "In my training, problem we want to avoid is overfitting, so we put 0 in the weight in our neuron network.\n",
        "\n",
        "Now we can see that we are getting pretty good results! The only problem is that it's pretty slow (~10 minutes). Remember what we saw in class about choosing the right learning rate $\\eta$? This is where Adam comes into play. It makes it faster!\n",
        "\n",
        "Let's make the neural network more complex and let's add regularization. Because we can see that there's some overfitting. The recall in the validation set is way below the recall in the training set. So we'll force the neural network to be easier."
      ],
      "metadata": {
        "id": "e7wI_Akug6Vn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCIVcwp6yaTa",
        "outputId": "5e419bde-7748-4fc1-9fe2-0fe0d63fa495"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1056/1056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - Recall: 0.6240 - loss: 0.6488\n",
            "Epoch 2/50\n",
            "\u001b[1m1056/1056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Recall: 0.7870 - loss: 0.5899\n",
            "Epoch 3/50\n",
            "\u001b[1m1056/1056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Recall: 0.7988 - loss: 0.5737\n",
            "Epoch 4/50\n",
            "\u001b[1m1056/1056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - Recall: 0.8002 - loss: 0.5761\n",
            "Epoch 5/50\n",
            "\u001b[1m1056/1056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Recall: 0.8001 - loss: 0.5687\n",
            "Epoch 6/50\n",
            "\u001b[1m1056/1056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Recall: 0.8116 - loss: 0.5666\n",
            "Epoch 7/50\n",
            "\u001b[1m1056/1056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Recall: 0.8105 - loss: 0.5817\n",
            "Epoch 8/50\n",
            "\u001b[1m1056/1056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - Recall: 0.8155 - loss: 0.5743\n",
            "Epoch 9/50\n",
            "\u001b[1m1056/1056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Recall: 0.8244 - loss: 0.5635\n",
            "Epoch 10/50\n",
            "\u001b[1m1056/1056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Recall: 0.8287 - loss: 0.5664\n",
            "Epoch 11/50\n",
            "\u001b[1m1056/1056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Recall: 0.8155 - loss: 0.5589\n",
            "Epoch 12/50\n",
            "\u001b[1m1056/1056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Recall: 0.8101 - loss: 0.5574\n",
            "Epoch 13/50\n",
            "\u001b[1m1056/1056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Recall: 0.8178 - loss: 0.5521\n",
            "Epoch 14/50\n",
            "\u001b[1m1056/1056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Recall: 0.8242 - loss: 0.5541\n",
            "Epoch 15/50\n",
            "\u001b[1m1056/1056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Recall: 0.8318 - loss: 0.5599\n",
            "Epoch 16/50\n",
            "\u001b[1m1056/1056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Recall: 0.8128 - loss: 0.5555\n",
            "Epoch 17/50\n",
            "\u001b[1m1056/1056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - Recall: 0.8204 - loss: 0.5588\n",
            "Epoch 18/50\n",
            "\u001b[1m1056/1056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Recall: 0.8296 - loss: 0.5482\n",
            "Epoch 19/50\n",
            "\u001b[1m1056/1056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Recall: 0.8156 - loss: 0.5537\n",
            "Epoch 20/50\n",
            "\u001b[1m1056/1056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Recall: 0.8232 - loss: 0.5605\n",
            "Epoch 21/50\n",
            "\u001b[1m1056/1056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - Recall: 0.8084 - loss: 0.5549\n",
            "Epoch 22/50\n",
            "\u001b[1m1056/1056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Recall: 0.8317 - loss: 0.5521\n",
            "Epoch 23/50\n",
            "\u001b[1m1056/1056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Recall: 0.8228 - loss: 0.5510\n",
            "Epoch 24/50\n",
            "\u001b[1m1056/1056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Recall: 0.8101 - loss: 0.5449\n",
            "Epoch 25/50\n",
            "\u001b[1m1056/1056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - Recall: 0.8364 - loss: 0.5483\n",
            "Epoch 26/50\n",
            "\u001b[1m1056/1056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Recall: 0.8194 - loss: 0.5525\n",
            "Epoch 27/50\n",
            "\u001b[1m1056/1056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Recall: 0.8309 - loss: 0.5373\n",
            "Epoch 28/50\n",
            "\u001b[1m1056/1056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Recall: 0.8315 - loss: 0.5390\n",
            "Epoch 29/50\n",
            "\u001b[1m1056/1056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - Recall: 0.8289 - loss: 0.5414\n",
            "Epoch 30/50\n",
            "\u001b[1m1056/1056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Recall: 0.8290 - loss: 0.5452\n",
            "Epoch 31/50\n",
            "\u001b[1m1056/1056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Recall: 0.8383 - loss: 0.5452\n",
            "Epoch 32/50\n",
            "\u001b[1m1056/1056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - Recall: 0.8334 - loss: 0.5381\n",
            "Epoch 33/50\n",
            "\u001b[1m1056/1056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - Recall: 0.8437 - loss: 0.5402\n",
            "Epoch 34/50\n",
            "\u001b[1m1056/1056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Recall: 0.8419 - loss: 0.5388\n",
            "Epoch 35/50\n",
            "\u001b[1m1056/1056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Recall: 0.8398 - loss: 0.5439\n",
            "Epoch 36/50\n",
            "\u001b[1m1056/1056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Recall: 0.8484 - loss: 0.5421\n",
            "Epoch 37/50\n",
            "\u001b[1m1056/1056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - Recall: 0.8337 - loss: 0.5386\n",
            "Epoch 38/50\n",
            "\u001b[1m1056/1056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Recall: 0.8276 - loss: 0.5388\n",
            "Epoch 39/50\n",
            "\u001b[1m1056/1056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Recall: 0.8508 - loss: 0.5430\n",
            "Epoch 40/50\n",
            "\u001b[1m1056/1056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Recall: 0.8385 - loss: 0.5355\n",
            "Epoch 41/50\n",
            "\u001b[1m1056/1056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - Recall: 0.8410 - loss: 0.5363\n",
            "Epoch 42/50\n",
            "\u001b[1m1056/1056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Recall: 0.8512 - loss: 0.5313\n",
            "Epoch 43/50\n",
            "\u001b[1m1056/1056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Recall: 0.8516 - loss: 0.5344\n",
            "Epoch 44/50\n",
            "\u001b[1m1056/1056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Recall: 0.8389 - loss: 0.5328\n",
            "Epoch 45/50\n",
            "\u001b[1m1056/1056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - Recall: 0.8515 - loss: 0.5341\n",
            "Epoch 46/50\n",
            "\u001b[1m1056/1056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Recall: 0.8595 - loss: 0.5408\n",
            "Epoch 47/50\n",
            "\u001b[1m1056/1056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - Recall: 0.8489 - loss: 0.5379\n",
            "Epoch 48/50\n",
            "\u001b[1m1056/1056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Recall: 0.8510 - loss: 0.5317\n",
            "Epoch 49/50\n",
            "\u001b[1m1056/1056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Recall: 0.8406 - loss: 0.5349\n",
            "Epoch 50/50\n",
            "\u001b[1m1056/1056\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Recall: 0.8478 - loss: 0.5347\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Define the neural network model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    keras.layers.Dropout(0.2),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dropout(0.2),\n",
        "    keras.layers.Dense(1, activation='sigmoid')  # Sigmoid for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "adam_optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=adam_optimizer, loss='binary_crossentropy', metrics=['Recall'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train_scaled, y_train, epochs=50, batch_size=64, verbose=1,\n",
        "                    class_weight=class_weight_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKsCm_uG91Vt",
        "outputId": "ea41a8da-16a6-46a1-d2d3-afc280380fcb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Validation Accuracy: 0.5892\n",
            "Validation Precision: 0.1068\n",
            "Validation Recall: 0.7211\n",
            "Validation F1 Score: 0.1861\n",
            "Validation Confusion Matrix:\n",
            "[[7851 5686]\n",
            " [ 263  680]]\n"
          ]
        }
      ],
      "source": [
        "# Predict probabilities\n",
        "y_proba = model.predict(X_val_scaled) # This is already a probability!\n",
        "\n",
        "# Make predictions\n",
        "y_pred = (y_proba > 0.5).astype(\"int32\")\n",
        "\n",
        "# Evaluate metrics\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "precision = precision_score(y_val, y_pred, zero_division=0)\n",
        "recall = recall_score(y_val, y_pred, zero_division=0)\n",
        "f1 = f1_score(y_val, y_pred, zero_division=0)\n",
        "cm = confusion_matrix(y_val, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Validation Precision: {precision:.4f}\")\n",
        "print(f\"Validation Recall: {recall:.4f}\")\n",
        "print(f\"Validation F1 Score: {f1:.4f}\")\n",
        "print(f\"Validation Confusion Matrix:\\n{cm}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the recall is getting higher, the validation precision will become lower\n",
        "\n",
        "In neurual network, we don't need to \"# Predict Probabilities\" because the result already in the range of (0,1)"
      ],
      "metadata": {
        "id": "oFpdrhO5hkeP"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}